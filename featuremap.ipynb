{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from learner import Learner\n",
    "\n",
    "# from advertorch.attacks import LinfPGDAttack\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0, 0, 0,), std=(1, 1, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = (224-2)//2\n",
    "# s = (s-2)//2\n",
    "# s = s-3\n",
    "# config = [\n",
    "#     ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "#     ('relu', [True]),\n",
    "#     ('bn', [32]),\n",
    "#     ('max_pool2d', [2, 2, 0]),\n",
    "#     ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "#     ('relu', [True]),\n",
    "#     ('bn', [32]),\n",
    "#     ('max_pool2d', [2, 2, 0]),\n",
    "#     ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "#     ('relu', [True]),\n",
    "#     ('bn', [32]),\n",
    "#     ('max_pool2d', [2, 1, 0]),\n",
    "#     ('flatten', []),\n",
    "#     ('linear', [5, 32 * s * s])\n",
    "# ]\n",
    "# # vars = torch.load(args.pretrained).to(device)\n",
    "\n",
    "# model = Learner(config, 3, 224)\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(torch.load(\"../model/conv3_5way_224.pt\"))\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../model/resnet18_5way_112.pt\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"eps_6.0\"\n",
    "image_paths = glob.glob(f\"../{PATH}/*\", )\n",
    "image_names = [os.path.basename(i) for i in image_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Model && Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorses = []\n",
    "vectors = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for k in range(len(image_paths)//2):\n",
    "        x = Image.open(image_paths[2 * k]) # attacked\n",
    "        x = transform(x).to(device).unsqueeze(0)\n",
    "\n",
    "        x2 = Image.open(image_paths[2 * k + 1]) # original\n",
    "        x2 = transform(x2).to(device).unsqueeze(0)\n",
    "\n",
    "        model_children = list(model.children())\n",
    "        counter = 0\n",
    "        names = []\n",
    "        outputs = []\n",
    "        errors = []\n",
    "        # vectors = []\n",
    "                \n",
    "        for i in range(len(model_children)-1):\n",
    "            if type(model_children[i]) == nn.Sequential:\n",
    "                for j in range(len(model_children[i])):\n",
    "                    x = model_children[i][j](x)\n",
    "                    x2 = model_children[i][j](x2)\n",
    "                    for child in model_children[i][j].children():\n",
    "                        #if type(child) == nn.Conv2d:\n",
    "                        counter+=1\n",
    "                        # model_weights.append(child.weight)\n",
    "                        names.append(str(child)[:str(child).index(\"(\")] + str(len(list(filter(lambda x:str(child)[:str(child).index(\"(\")] in x, names)))))\n",
    "                        # print(str(child)[:str(child).index(\"(\")] + str(len(list(filter(lambda x:str(child)[:str(child).index(\"(\")] in x, names)))))\n",
    "                        outputs.append(x)\n",
    "                        outputs.append(x2)\n",
    "                        outputs.append(torch.abs(x-x2))\n",
    "                        errors.append(torch.abs(x-x2))\n",
    "\n",
    "            else:\n",
    "                x = model_children[i](x)\n",
    "                x2 = model_children[i](x2)\n",
    "                # if type(model_children[i]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                # model_weights.append(model_children[i].weight)\n",
    "                names.append(str(model_children[i])[:str(model_children[i]).index(\"(\")] + str(len(list(filter(lambda x:str(model_children[i])[:str(model_children[i]).index(\"(\")] in x, names)))))\n",
    "                outputs.append(x)\n",
    "                outputs.append(x2)\n",
    "                outputs.append(torch.abs(x-x2))\n",
    "                errors.append(torch.abs(x-x2))\n",
    "\n",
    "                if i == len(model_children)-2: # feature\n",
    "                    vectors.append(x.view(-1))\n",
    "                    vectors.append(x2.view(-1))\n",
    "                    labels.append(int(image_names[2 * k].split(\"_\")[-1][:-4]))\n",
    "                    labels.append(-1*int(image_names[2 * k + 1].split(\"_\")[-1][:-4]))\n",
    "\n",
    "        errorses.append(errors[:])\n",
    "        # print(erros[0][0][0][0][0])\n",
    "\n",
    "        # print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 10\n",
    "FEATURE_MAP_NUM = 64\n",
    "\n",
    "processed = []\n",
    "for feature_map in outputs[LAYER * 3:(LAYER + 1) * 3]:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    for features in feature_map[:FEATURE_MAP_NUM]:\n",
    "        processed.append(features.data.cpu().numpy())\n",
    "    # processed.append(gray_scale.data.cpu().numpy())\n",
    "# fig = plt.figure(figsize=(11, 500))\n",
    "\n",
    "fig = plt.figure(figsize=(200, 11))\n",
    "\n",
    "# fig = plt.figure(figsize=(50, 50))\n",
    "# for i in range(len(processed)):\n",
    "\n",
    "print(len(processed))\n",
    "for i in range(len(processed)):\n",
    "    a = fig.add_subplot(3, FEATURE_MAP_NUM, i+1)\n",
    "    imgplot = plt.imshow(processed[i], vmin=0, vmax=1)\n",
    "    a.axis(\"off\")\n",
    "    # a.set_title(f\"{names[i//3]}_{i//3}\", fontsize=10)\n",
    "plt.savefig(f'feature_maps_{PATH}_conv_{LAYER}.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Error Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errorses))\n",
    "mean_errorses = []\n",
    "\n",
    "for errors in errorses:\n",
    "    mean_errors = []\n",
    "    for error in errors:\n",
    "        _, c, h, w = error.shape\n",
    "\n",
    "        error_sum = torch.sum(error, (1, 2, 3))\n",
    "        error_mean = torch.abs((error_sum / (c * h * w))).item()\n",
    "        \n",
    "        mean_errors.append(error_mean)\n",
    "        # print(error.shape)\n",
    "        # print(error_mean)\n",
    "\n",
    "    mean_errorses.append(mean_errors)\n",
    "\n",
    "    # print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errorses_tensor = torch.tensor(mean_errorses)\n",
    "\n",
    "mean_errorses_mean = torch.mean(mean_errorses_tensor, dim=0)\n",
    "\n",
    "print(mean_errorses_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))  # Width: 10 inches, Height: 6 inches\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(names, mean_errorses_mean)\n",
    "plt.xticks(fontsize=5)\n",
    "\n",
    "# plt.ylim(0, 1.0)\n",
    "\n",
    "plt.savefig('error.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.stack(vectors).cpu()\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=2, n_neighbors=8, min_dist=0.3, metric=\"euclidean\", random_state=50)\n",
    "\n",
    "embedding = reducer.fit_transform(features)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "markers = ['o', 's', '^', 'x', 'D']\n",
    "\n",
    "for i in range(embedding.shape[0]//2):\n",
    "    # print(labels[i])\n",
    "\n",
    "    plt.scatter(embedding[2 * i,0], embedding[2 * i,1], label=abs(labels[2 * i]), marker=markers[labels[2 * i + 1]], color=\"blue\", s=40) # attack\n",
    "    plt.scatter(embedding[2 * i + 1,0], embedding[2 * i + 1,1], label=abs(labels[2 * i + 1]), marker=markers[labels[2 * i + 1]], color=\"orange\", s=40) # origin\n",
    "    \n",
    "plt.savefig('diff_6.0.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
